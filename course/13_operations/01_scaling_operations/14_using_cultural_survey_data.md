# Using Cultural Survey Data

How to effectively read, analyze, and take action on cultural survey results—a practical guide for executives and leaders who want to build trust by following through on addressing team concerns.

## The Context

**At Stripe:** When I was at Stripe, I reworked the hiring process for Director-plus engineering managers. My goal was to better evaluate polished senior leaders who always said the right thing. I wanted to find the real beliefs and behaviors underneath all the polish. One interview I created focused on how candidates reviewed cultural survey results.

**Cultural surveys are common:** Almost every scaled company runs some sort of cultural survey. There are a variety of vendors like CultureAmp or Lattice, and some companies build their own tools in house. Cultural surveys ask questions about the experience working in the company, cross-team collaboration, compensation, and so on. The results are tallied together, and reports are generated for each manager about their team, and the executive team gets a report about the company overall.

**Why they matter:** Relative to most other running-the-business responsibilities, senior leaders usually don't spend too much time on cultural survey results, but they're a great lens into their data literacy and how they prioritize limited resources to address a very broad problem space. This is just as true of your existing executive team—and even you—as it is of potential hires, and they're a valuable mechanism for earning credibility with your team by following through to address their concerns.

## Reading Results

**Quick advice to effectively review survey data:**
- Spend a couple hours digesting the results
- Focus more on absolute scores than on relative scores: a high score is still high, even if it's relatively down a bit
- Take the time to identify all issues, rather than getting caught up in the first couple you notice

**The formalized approach:**

**1. Check access before starting**
- Check if you have whole company access or only have access to the engineering report
- If it's the latter, bring it up at the next executive team meeting
- If your executive team leads the company, but isn't trusted to view the whole company's survey results, something doesn't make sense there, and it should be fixed
- The executive team may find it uncomfortable to see each other's survey results, but that transparency to one another is part of an executive team gelling together
- Further, it's very helpful to see if, e.g. Engineering and Product in a given business unit are both frustrated, rather than having to reverse engineer that narrative by hand
- The broader comments are also helpful, as you may identify areas where other functions are frustrated working with Engineering, which is valuable feedback that's easily lost without full report access

**2. Create a private document for notes**
- Start by creating a private document to collect your notes on the survey
- For each major theme you identify, take a screen capture of the data that raises the issue, and add a few sentences of commentary
- This is your staging ground for analysis, not your final product, so don't worry about keeping it tidy

**3. Understand population sizes**
- Get a sense of the size of your populations in the report
- This helps to build an intuition around what kinds of results might be statistically significant
- Most changes will be significant in an engineering organization of 2,000, but if your technical program manager team is only seven people, then even an extreme change probably isn't significant

**Be skeptical of narratives:** Survey tools are strongly incentivized to produce narratives, even if the narrative is relatively weak. This means that you have to be cautiously skeptical of the analysis, particularly any that lacks statistical significance. That's not to say that you should ignore anything without statistical significance, but instead use the right sort of data: comments, follow ups, and so on, rather than raw numbers.

**4. Skim and categorize**
- Skim through the entire report, and start to group insights into three categories: things to celebrate, things to proactively address, and things to acknowledge
- The groupings aren't final, so don't spend too much time on them
- Make sure to capture highlights in addition to concerns: especially when things are going poorly, you'll never want to present a purely negative update

**5. Check previous investments**
- If you identified areas of investment after your last survey, how did you perform there?
- If you saw an improvement, highlight the success
- If you didn't, form a hypothesis for why you didn't have an impact

**6. Focus on extremes**
- Focus on your highest and lowest absolute ratings
- Have these changed? Did you expect them to change?

**7. Focus on rapid changes**
- Focus on ratings that are changing the fastest
- What's driving the rapid shift?

**8. Compare across cohorts**
- Identify what stands out when you compare across cohorts
- How do different managers perform?
- How about cohorts of tenure, gender, and location?

**9. Read every comment**
- Read every single comment, and copy the most relevant ones over to your notes document
- What are the subjective pieces of feedback that change how you interpret the data?
- What are comments you might quote when sharing a summary?

**10. Discuss with a peer**
- End this analysis process by spending an hour with a peer, e.g. the head of product, to talk through your findings
- Do this after they've spent time with their own report
- Sometimes you'll identify connected themes across the orgs, but more importantly you'll often find gaps in your analysis by talking it through

**Who to discuss with:** You can, in theory, do this with someone on your team, but you'll end up either putting them in a messy position discussing their peers or having to avoid the thorniest issues, both of which are bad outcomes.

**At this point:** You will have a good sense of the data, and it's time to move on to the fun part: figuring out what to do with it.

## Taking Action on the Results

**The problem:** You'll often see teams spend a great deal of time running the survey, even more time analyzing the results, but never actually use that analysis for anything. This frustrates the team, who become trained to ignore future surveys.

**The other extreme:** Very earnest leaders commit to fixing everything. Your team will initially love you for this, but it won't hit quite the same way six months later when you have to report that you've made very little progress.

**The middle path:** Success is walking the middle path: identify a few important areas where you believe you can make real progress, and then actually do the work.

**The standard pattern:**

**1. Address acute issues immediately**
- If you identify any acutely serious issues, take action immediately
- For example, a manager whose team is in open revolt, or an ethical issue is raised

**2. Select 2-3 investment areas**
- Use your analysis notes to select two to three areas you want to invest into until the next survey is run
- For example, increasing representation for Staff-plus engineers in key decision making forums, or increasing the sense of belonging for remote employees

**3. Create a shareable document**
- Edit your notes and new investment areas into a document you're comfortable sharing with the broader organization
- I would err on being transparent, but a very optimistic sort of transparency: most things that are relatively down are still absolutely high, a recent trend down is important but we're still significantly higher than historical averages, and so on

**4. Review with multiple stakeholders**
- Review this document with your direct reports, likely in your team meeting
- Review with your People or Human Resources partner
- Review with your peers on the executive team
- Review the document with two or three trusted individual contributors within Engineering who will likely be more sensitive to the kinds of issues that are easier to miss as an executive

**5. Incorporate feedback carefully**
- As you get feedback from reviewers, think through the feedback and incorporate it to your best judgment
- Sometimes reviewers manufacture feedback to have something to say, but my reviewers have always found something important that I've missed, so I think it's important to listen carefully to the feedback here, even if it doesn't initially resonate

**6. Define explicit, verifiable actions**
- For the areas you want to invest in, make sure you have explicit, verifiable actions to take
- If these are too abstract, then it's hard to build your team's trust in you because it will be ambiguous whether you actually followed through on your commitments

**7. Share and discuss**
- Share the document with your organization (via email, chat, or whatnot) and schedule a meeting to discuss the findings and priorities with the entire engineering organization
- I often repurpose the Engineering Q&A sessions for this discussion

**8. Follow up monthly**
- Follow up on a monthly cadence on progress against your action items
- I often include the updates in my weekly updates to the organization

**9. Mention improvements next survey**
- Make sure to mention these improvements when you introduce the next round of cultural surveying
- The team will take the survey much more seriously if they know you took action last time
- From a mechanical perspective, this will also help you score higher on questions on the survey related to whether you actually make improvements from last time
- Unless you do this, any new hire simply won't know if you've made any improvements

**The outcome:** Although this is a straightforward process, it'll build the team's trust in you, and a stronger team culture. Executives are rarely held accountable unless they expose themselves to accountability, and this is a valuable opportunity to hold yourself accountable to your team. As you hold yourself accountable, it'll become increasingly easy to hold your team accountable as well.

## Questions to Ask

**The debate:** Some executive teams will debate adding questions every time a cultural survey is about to run. I'm sympathetic to the fundamental concern: questions may be poorly worded, and they'll never ask about whatever topic is particularly top of mind.

**The recommendation:** While it's important to ensure you get good coverage in your questions, I generally think the default questions are good enough, and that it's not worthwhile to change.

**Two types of data from cultural surveys:**

**1. Ratings on various questions**
- Valuable because you can compare across cohorts
- Become even more useful as you can see their trend over time
- **Expensive to change:** Each change wipes out any historical context on the question
- Changes away from the default questions also means you can't compare your results against wider industry benchmarks
- **Recommendation:** Generally recommend against changing the first type of question unless folks taking the survey are frequently confused by a particular question
- For example, you'll often hear confusion between terms like "the Management Team" and "your manager" because the wider company doesn't know that the executive team refers to itself as "the Management Team." This kind of confusion has already invalidated the results, so a change that increases clarity is still more valuable than preserving continuity.

**2. Free-form responses**
- Provide subjective context
- **Relatively cheap to change:** There is no history to wipe out
- However, my experience is that if folks have something to say, they will say it anywhere, even if the question is somewhat unrelated
- Adding more free-form questions doesn't change that, so as long as you have a handful of open ended questions, I wouldn't worry about adding more

**The conclusion:** Taken in sum, it's worth evaluating these questions before your first rollout, but repeated arguments about changing these questions is just executive bikeshedding.

## Starting and Frequency

**When to start:** In small organizations where you have a genuine relationship with every member of the team, you probably won't get too much from running a cultural survey. However, as your organization grows, they become more and more useful. I find Dunbar's number, roughly 150, to be a good point to ensure you're running one of these surveys.

**Frequency:** Most organizations run these twice a year, which is a reasonable amount. If you want a more principled way to determine the right frequency, consider how much time you're willing to invest into addressing the issues that get raised. If you're already struggling to address concerns from biannual surveys, then it doesn't make sense to run more frequent surveys. You'll just annoy folks who take them, who will complain that you're running another survey before addressing the previously raised concerns.

## It Can Be Uncomfortable

**The reality:** While I've often been proud of the cultural survey scores I receive, sometimes I've been pretty embarrassed. I've been called out for not paying attention to the team's priorities. I've tried to prioritize the remote working experience, but had it regress rather than improve. I've had below average scores and bad scores.

**The approach:** Take a moment, and be uncomfortable with it. It means that you care! Then, lean into the feedback, and use it to motivate you to address the issues at hand.

## Key Takeaways

1. **Cultural surveys are valuable lenses** - They reveal data literacy and how leaders prioritize limited resources to address a broad problem space.

2. **Reading results requires structure** - Follow a systematic approach: check access, create notes, understand population sizes, categorize, compare, read comments, discuss with peers.

3. **Focus on absolute scores** - A high score is still high, even if relatively down. Don't get caught up in relative changes alone.

4. **Be skeptical of narratives** - Survey tools are incentivized to produce narratives. Be cautiously skeptical, especially of analysis lacking statistical significance.

5. **Take action on 2-3 areas** - Don't commit to fixing everything, but don't ignore results. Identify a few areas where you can make real progress.

6. **Be transparent and optimistic** - Share results broadly, but frame them optimistically: things that are relatively down are often still absolutely high.

7. **Define explicit, verifiable actions** - Abstract commitments don't build trust. Make sure actions are clear and measurable.

8. **Follow up monthly** - Regular updates on progress build trust and show you're taking the survey seriously.

9. **Don't change questions unnecessarily** - Default questions preserve historical context and allow industry benchmarking. Only change if genuinely confusing.

10. **Start around 150 people (Dunbar's number)** - Before that, you have genuine relationships. After that, surveys become increasingly useful.

11. **Run twice a year typically** - Frequency should match your capacity to address concerns. If struggling with biannual, don't run more frequently.

12. **Embrace discomfort** - Bad scores are uncomfortable, but that means you care. Use it as motivation to address issues.

---

**Source:** [Using cultural survey data](https://lethain.com/using-cultural-survey-data/), Irrational Exuberance by Will Larson (March 13, 2023). This is an unedited chapter from O'Reilly's "The Engineering Executive's Primer." Will Larson is the author of "An Elegant Puzzle," "Staff Engineer," "The Engineering Executive's Primer," and "Crafting Engineering Strategy."

